{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a)\n",
    "\n",
    "\n",
    "class Knn:\n",
    "    # k-Nearest Neighbor class object for classification training and testing\n",
    "    def _init_(self):\n",
    "        self.x_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        # Save the training data to properties of this class\n",
    "        self.x_train = x\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, x, k):\n",
    "        y_hat = []  # Variable to store the estimated class label for\n",
    "        # Calculate the distance from each vector in x to the training data\n",
    "\n",
    "        euclidean_distance = np.sum((self.x_train[:, np.newaxis] - x) * 2, axis=2) * 0.5\n",
    "\n",
    "        for column in euclidean_distance.T:\n",
    "            # here we obtain the indices of the k nearest neighbors.\n",
    "            k_smallest_d_indices = np.argsort(column)[:k]\n",
    "            y_predicted = round(np.mean(self.y_train[k_smallest_d_indices]))\n",
    "            y_hat.append(y_predicted)\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "\n",
    "# Metric of overall classification accuracy\n",
    "#  (a more general function, sklearn.metrics.accuracy_score, is also available)\n",
    "\n",
    "\n",
    "def accuracy(y, y_hat):\n",
    "    nvalues = len(y)\n",
    "    accuracy = sum(y == y_hat) / nvalues\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function for class classifier\n",
    "\n",
    "X = np.array(\n",
    "    [[0, 3, 0], [2, 0, 0], [0, 1, 3], [0, 1, 2], [-1, 0, 1], [1, 1, 1]]\n",
    ")  # self.x.train\n",
    "y = np.array([1, 1, 1, 0, 0, 1])  # self y train\n",
    "y_dict = {index: value for index, value in enumerate(y)}\n",
    "X_test = np.array([[0, 0, 0]])  # X\n",
    "\n",
    "\n",
    "def keep_highest(row):\n",
    "    unique_values, counts = np.unique(row, return_counts=True)\n",
    "    max_count_v = unique_values[np.argmax(counts)]\n",
    "    return max_count_v\n",
    "\n",
    "\n",
    "k = 3\n",
    "matrix = np.empty((0, X.shape[0]))\n",
    "for i in X_test:  # X\n",
    "    e_distance = np.sqrt(np.sum((X - i) ** 2, axis=1)).reshape(1, -1)\n",
    "    matrix = np.vstack((matrix, e_distance))\n",
    "\n",
    "matrix_i = np.argpartition(matrix, k, axis=1)[:, :k]\n",
    "matrix_c = np.vectorize(y_dict.get)(matrix_i)\n",
    "y_pred = np.apply_along_axis(keep_highest, axis=1, arr=matrix_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test class with exercise 3\n",
    "\n",
    "x_train = np.array([[0, 3, 0], [2, 0, 0], [0, 1, 3], [0, 1, 2], [-1, 0, 1], [1, 1, 1]])\n",
    "y_train = np.array([0, 0, 0, 1, 1, 0])\n",
    "\n",
    "X_test = np.array([[0, 0, 0]])\n",
    "k = 3\n",
    "\n",
    "test_Knn = Knn()\n",
    "test_Knn.fit(x_train, y_train)\n",
    "test_Knn.predict(X_test, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 5 plots\n",
    "\n",
    "X, y = sklearn.datasets.make_moons(\n",
    "    n_samples=1000, shuffle=True, noise=0.35, random_state=None\n",
    ")\n",
    "r_indexes_1 = np.random.choice(len(X), size=100, replace=True)\n",
    "r_indexes_2 = np.random.choice(len(X), size=100, replace=True)\n",
    "r_indexes_3 = np.random.choice(len(X), size=100, replace=True)\n",
    "\n",
    "np.random.seed(333)\n",
    "\n",
    "X_1 = X[r_indexes_1]\n",
    "y_1 = y[r_indexes_1]\n",
    "\n",
    "X_2 = X[r_indexes_2]\n",
    "y_2 = y[r_indexes_2]\n",
    "\n",
    "X_3 = X[r_indexes_3]\n",
    "y_3 = y[r_indexes_3]\n",
    "\n",
    "\n",
    "neigh_01 = KNeighborsClassifier(n_neighbors=1)\n",
    "neigh_25 = KNeighborsClassifier(n_neighbors=25)\n",
    "neigh_50 = KNeighborsClassifier(n_neighbors=50)\n",
    "\n",
    "\n",
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6), (ax7, ax8, ax9)) = plt.subplots(\n",
    "    3, 3, figsize=(20, 12)\n",
    ")\n",
    "\n",
    "# S1\n",
    "neigh_01.fit(X_1, y_1)\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "Z = neigh_25.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.sca(ax1)\n",
    "plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors=\"k\")\n",
    "\n",
    "\n",
    "#  k=25\n",
    "\n",
    "neigh_25.fit(X_1, y_1)\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "Z = neigh_25.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.sca(ax2)\n",
    "plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors=\"k\")\n",
    "\n",
    "\n",
    "#  k=50\n",
    "\n",
    "neigh_50.fit(X_1, y_1)\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "Z = neigh_50.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.sca(ax3)\n",
    "plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors=\"k\")\n",
    "\n",
    "\n",
    "# S2\n",
    "neigh_01.fit(X_2, y_2)\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "Z = neigh_25.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.sca(ax4)\n",
    "plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors=\"k\")\n",
    "\n",
    "\n",
    "#  k=25\n",
    "\n",
    "neigh_25.fit(X_2, y_2)\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "Z = neigh_25.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.sca(ax5)\n",
    "plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors=\"k\")\n",
    "\n",
    "#  k=50\n",
    "\n",
    "neigh_50.fit(X_2, y_2)\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "Z = neigh_50.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.sca(ax6)\n",
    "plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors=\"k\")\n",
    "\n",
    "\n",
    "# S3\n",
    "neigh_01.fit(X_3, y_3)\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "Z = neigh_25.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.sca(ax7)\n",
    "plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors=\"k\")\n",
    "\n",
    "\n",
    "#  k=25\n",
    "\n",
    "neigh_25.fit(X_3, y_3)\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "Z = neigh_25.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.sca(ax8)\n",
    "plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors=\"k\")\n",
    "\n",
    "\n",
    "#  k=50\n",
    "\n",
    "neigh_50.fit(X_3, y_3)\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "Z = neigh_50.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.sca(ax9)\n",
    "plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors=\"k\")\n",
    "\n",
    "\n",
    "ax1.set_title(\"Decision Boundary KKN (k=1)\")\n",
    "ax2.set_title(\"Decision Boundary KKN (k=25)\")\n",
    "ax3.set_title(\"Decision Boundary KKN (k=50)\")\n",
    "\n",
    "y_axis_labels = [\"Sample 1\", \"Sample 2\", \"Sample 3\"]\n",
    "\n",
    "# Set titles for each y-axis\n",
    "for ax, y_label in zip([ax1, ax4, ax7], y_axis_labels):\n",
    "    ax.set_ylabel(y_label)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (d)\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(13, 13))\n",
    "\n",
    "knn = [\n",
    "    [Knn_1_1, Knn_2_1, Knn_3_1],\n",
    "    [Knn_1_25, Knn_2_25, Knn_3_25],\n",
    "    [Knn_1_50, Knn_2_50, Knn_3_50],\n",
    "]\n",
    "k = [1, 25, 50]\n",
    "X_subset = [X_1, X_2, X_3]\n",
    "y_subset = [y_1, y_2, y_3]\n",
    "\n",
    "for j in range(len(knn)):\n",
    "    for i, (X, y, estimator) in enumerate(zip(X_subset, y_subset, knn[j])):\n",
    "        disp = DecisionBoundaryDisplay.from_estimator(\n",
    "            estimator,\n",
    "            X,\n",
    "            response_method=\"predict\",\n",
    "            plot_method=\"pcolormesh\",\n",
    "            xlabel=\"x1\",\n",
    "            ylabel=\"x2\",\n",
    "            shading=\"auto\",\n",
    "            alpha=0.5,\n",
    "            ax=axs[i, j],\n",
    "        )\n",
    "\n",
    "        scatter = axs[i, j].scatter(X[:, 0], X[:, 1], c=y, edgecolors=\"k\")\n",
    "\n",
    "        axs[i, j].legend(\n",
    "            scatter.legend_elements()[0],\n",
    "            np.unique(y),\n",
    "            loc=\"lower left\",\n",
    "            title=\"Classes\",\n",
    "        )\n",
    "\n",
    "        axs[i, j].set_title(\n",
    "            f\"\\nDecision Boundaries for KNN Classifiers\\nDataset {i+1} ; k = {k[j]}\\n\"\n",
    "        )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_azis=range (1, 501)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "plt.plot(x_azis, score_test_l, c='grey', label='test')\n",
    "plt.plot(x_azis, score_train_l, c='orange', label='train')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)  \n",
    "\n",
    "plt.xticks(np.arange(min(x_azis), max(x_azis)+1, 24))\n",
    "plt.yticks(np.arange(0, 0.185, 0.015))\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Classification error')\n",
    "plt.title('Classification error for K=1 to K=500')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "\n",
    "Xtrain, ytrain = sklearn.datasets.make_moons(\n",
    "    n_samples=1000, shuffle=True, noise=0.35, random_state=None\n",
    ")\n",
    "\n",
    "Xtest, ytest = sklearn.datasets.make_moons(\n",
    "    n_samples=1000, shuffle=True, noise=0.35, random_state=None\n",
    ")\n",
    "\n",
    "\n",
    "def accuracy(y, y_hat):\n",
    "    nvalues = len(y)\n",
    "    accuracy = sum(y == y_hat) / nvalues\n",
    "    return accuracy\n",
    "\n",
    "score_train_l=[]\n",
    "score_test_l=[]\n",
    "\n",
    "for i in range (1, 501):\n",
    "    knn_train=KNeighborsClassifier(n_neighbors=i).fit(Xtrain, ytrain)\n",
    "    y_hat_train=knn_train.predict(Xtrain)\n",
    "    score_train=1-accuracy(ytrain,y_hat_train,)\n",
    "    score_train_l.append(score_train)\n",
    "\n",
    "    knn_test=KNeighborsClassifier(n_neighbors=i).fit(Xtrain, ytrain)\n",
    "    y_hat_test=knn_test.predict(Xtest)\n",
    "    score_test=1-accuracy(ytest,y_hat_test)\n",
    "    score_test_l.append(score_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "plt.scatter(x_train, y_train, c=\"orange\")\n",
    "#plt.plot(x, regression_line, color='red', label='Regression Line')\n",
    "\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = train.x.values\n",
    "x_train = np.log(x_train)\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "\n",
    "plt.scatter(x_train, y_train, c=\"orange\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Training data log\")\n",
    "plt.show()\n",
    "\n",
    "x_train = train.x.values\n",
    "x_train = np.sin(x_train)\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "plt.scatter(x_train, y_train, c=\"orange\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Training data sin\")\n",
    "plt.show()\n",
    "\n",
    "x_train = train.x.values\n",
    "x_train = np.power(x_train, 2)\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "\n",
    "plt.scatter(x_train, y_train, c=\"orange\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Training data square\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**(7 d)** Visualize the model fit to the training data. Using both of the models you created in parts (b) and (c), plot the original data (as a scatter plot) AND the curves representing your models (each as a separate curve) from (b) and (c).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(x_train, y_train_hat_2, c=\"orange\")\n",
    "# plt.plot(x, regression_line, color='red', label='Regression Line')\n",
    "\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Training data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Sort the data by x_train\n",
    "sorted_indices = np.argsort(x_train.flatten())\n",
    "x_train_sorted = x_train[sorted_indices]\n",
    "y_train_hat_2_sorted = y_train_hat_2[sorted_indices]\n",
    "\n",
    "# Plot the curve\n",
    "plt.plot(x_train_sorted, y_train_hat_2_sorted, color=\"orange\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Training data\")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
